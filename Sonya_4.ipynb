{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sonya #4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOP6yQZX+ZI5g75iJppKgEh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andresalcaraaz/Netflix-Project-2-ETL-Data/blob/master/Sonya_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0sCXjrrusjf",
        "outputId": "2a3dc6e4-1a82-45c7-9dbc-3a7d193a10fa"
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.2'\n",
        "spark_version = 'spark-3.1.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r                                                                               \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r0% [Release.gpg gpgv 697 B] [Connecting to archive.ubuntu.com] [Connecting to s\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,476 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,173 kB]\n",
            "Fetched 4,901 kB in 3s (1,599 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJR3Fh0ju79-"
      },
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import StructType,StructField,StringType, DateType,IntegerType\n",
        "\n",
        "# we are going to use this to time our queries.\n",
        "import time\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7Ru3zWCvFsW"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-netflix/filterNames.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"filterNames.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "df.createOrReplaceTempView('names')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7VP5W09GyiI",
        "outputId": "52b4b5a2-5f54-41bc-8158-755d6006f07a"
      },
      "source": [
        "#spark.sql(\"SELECT * FROM names WHERE primaryprofession = 'actor' OR primaryprofession = 'actress' \").show()\n",
        "df = spark.sql(\"SELECT * FROM names WHERE primaryprofession in ('actor', 'actress') \")\n",
        "clean_professions_df = df.drop(\"birthyear\",\"knownfortitles\",\"knownFor\",\"deathyear\")\n",
        "clean_professions_df.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------------------+-----------------+\n",
            "|   nconst|         primaryname|primaryprofession|\n",
            "+---------+--------------------+-----------------+\n",
            "|nm0458601|          Mark Kleid|            actor|\n",
            "|nm0458664|          Bart Klein|            actor|\n",
            "|nm0458866|        Leslie Klein|          actress|\n",
            "|nm0458929|         Paula Klein|          actress|\n",
            "|nm0459041|     Kevin Kleinberg|            actor|\n",
            "|nm0459062| Adelheid Kleineidam|          actress|\n",
            "|nm0459073|      Sergio Kleiner|            actor|\n",
            "|nm0459084|  Franziska Kleinert|          actress|\n",
            "|nm0459106|   Stefan Kleinkrieg|            actor|\n",
            "|nm0459132|    Manny Kleinmuntz|            actor|\n",
            "|nm0459186|      Maria Klejdysz|          actress|\n",
            "|nm0459299|     Ladislav Klepal|            actor|\n",
            "|nm0459318|      Kamaljeet Kler|          actress|\n",
            "|nm0459364|        Aaron Kleven|            actor|\n",
            "|nm0459522|      Nele Savicenko|          actress|\n",
            "|nm0459580|        Atila Klince|            actor|\n",
            "|nm0459683|       Kent Klineman|            actor|\n",
            "|nm0459823|       Rüdiger Klink|            actor|\n",
            "|nm0459991|         Enn Klooren|            actor|\n",
            "|nm0460037|Romuald Andrzej Klos|            actor|\n",
            "+---------+--------------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrlotbF_0NnZ"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-netflix/filteredPrincipals.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df1 = spark.read.csv(SparkFiles.get(\"filteredPrincipals.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "df1.createOrReplaceTempView('names1')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUXJIslVwqaT",
        "outputId": "192bbc61-b2f8-4cb1-cc3a-7ca956207b60"
      },
      "source": [
        "character.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+--------+---------+---------------+----+-----------------+\n",
            "|    tconst|ordering|   nconst|       category| job|       characters|\n",
            "+----------+--------+---------+---------------+----+-----------------+\n",
            "|tt12189034|       6|nm5943320|          actor|null|      \"[\"\"Lee\"\"]\"|\n",
            "|tt12189034|       6|nm5943320|          actor|null|      \"[\"\"Lee\"\"]\"|\n",
            "|tt12189034|       6|nm5943320|          actor|null|      \"[\"\"Lee\"\"]\"|\n",
            "|tt12189034|       6|nm5943320|          actor|null|      \"[\"\"Lee\"\"]\"|\n",
            "|tt12189034|       8|nm7672770|          actor|null|\"[\"\"Detective\"\"]\"|\n",
            "|tt12189034|       8|nm7672770|          actor|null|\"[\"\"Detective\"\"]\"|\n",
            "|tt12189034|       8|nm7672770|          actor|null|\"[\"\"Detective\"\"]\"|\n",
            "|tt12189034|       8|nm7672770|          actor|null|\"[\"\"Detective\"\"]\"|\n",
            "|tt12190374|       3|nm0767339|cinematographer|null|             null|\n",
            "|tt12190374|       3|nm0767339|cinematographer|null|             null|\n",
            "|tt12190374|       3|nm0767339|cinematographer|null|             null|\n",
            "|tt12190374|       3|nm0767339|cinematographer|null|             null|\n",
            "| tt1219128|       2|nm2698001|        actress|null|             null|\n",
            "| tt1219128|       2|nm2698001|        actress|null|             null|\n",
            "| tt1219128|       2|nm2698001|        actress|null|             null|\n",
            "| tt1219128|       2|nm2698001|        actress|null|             null|\n",
            "|tt12191898|       2|nm8435168|          actor|null|    \"[\"\"Quavo\"\"]\"|\n",
            "|tt12191898|       2|nm8435168|          actor|null|    \"[\"\"Quavo\"\"]\"|\n",
            "|tt12191898|       2|nm8435168|          actor|null|    \"[\"\"Quavo\"\"]\"|\n",
            "|tt12191898|       2|nm8435168|          actor|null|    \"[\"\"Quavo\"\"]\"|\n",
            "+----------+--------+---------+---------------+----+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58W3EQCJzLAt",
        "outputId": "5c201841-513c-461d-b4f5-17ed46c3d45c"
      },
      "source": [
        "#spark.sql(\"SELECT * FROM names WHERE primaryprofession = 'actor' OR primaryprofession = 'actress' \").show()\n",
        "df1 = spark.sql(\"SELECT * FROM names1 WHERE category in ('actor', 'actress') \")\n",
        "category = df.drop(\"tconst\",\"ordering\",\"job\")\n",
        "category.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------------------+---------+---------+-----------------+--------------------+---------+\n",
            "|   nconst|         primaryname|birthyear|deathyear|primaryprofession|      knownfortitles| knownFor|\n",
            "+---------+--------------------+---------+---------+-----------------+--------------------+---------+\n",
            "|nm0458601|          Mark Kleid|     null|     null|            actor|tt0105041,tt01120...|tt0277615|\n",
            "|nm0458664|          Bart Klein|     null|     null|            actor|tt0830854,tt03064...|tt0306413|\n",
            "|nm0458866|        Leslie Klein|     null|     null|          actress|           tt0462601|tt0462601|\n",
            "|nm0458929|         Paula Klein|     null|     null|          actress|tt1060234,tt01174...|tt1258120|\n",
            "|nm0459041|     Kevin Kleinberg|     1982|     null|            actor|tt0277249,tt57770...|tt0256278|\n",
            "|nm0459062| Adelheid Kleineidam|     1966|     null|          actress|tt0178142,tt04372...|tt0437294|\n",
            "|nm0459073|      Sergio Kleiner|     1936|     null|            actor|tt0495921,tt00616...|tt0495921|\n",
            "|nm0459084|  Franziska Kleinert|     1955|     null|          actress|tt0765055,tt02934...|tt0293425|\n",
            "|nm0459106|   Stefan Kleinkrieg|     null|     null|            actor|tt1076942,tt07812...|tt0921714|\n",
            "|nm0459132|    Manny Kleinmuntz|     1922|     null|            actor|tt0326856,tt04557...|tt0455715|\n",
            "|nm0459186|      Maria Klejdysz|     1927|     2009|          actress|tt0381637,tt15114...|tt1511447|\n",
            "|nm0459299|     Ladislav Klepal|     1937|     2002|            actor|tt0230183,tt01046...|tt0349819|\n",
            "|nm0459318|      Kamaljeet Kler|     null|     null|          actress|           tt0240515|tt0240515|\n",
            "|nm0459364|        Aaron Kleven|     null|     null|            actor|tt0425483,tt02002...|tt0425483|\n",
            "|nm0459522|      Nele Savicenko|     1957|     null|          actress|tt0234056,tt09298...|tt3274484|\n",
            "|nm0459580|        Atila Klince|     1958|     null|            actor|tt1649442,tt02749...|tt0243232|\n",
            "|nm0459683|       Kent Klineman|     null|     null|            actor|tt0118437,tt31165...|tt0229328|\n",
            "|nm0459823|       Rüdiger Klink|     1971|     null|            actor|tt4193400,tt02505...|tt4193400|\n",
            "|nm0459991|         Enn Klooren|     1940|     2011|            actor|tt0367480,tt03124...|tt0367480|\n",
            "|nm0460037|Romuald Andrzej Klos|     1956|     null|            actor|tt0384766,tt04073...|tt0385359|\n",
            "+---------+--------------------+---------+---------+-----------------+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHJQcegs0n1D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSiRea4roiMO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L0JH0zm9VCj"
      },
      "source": [
        "#clean_professions_df[['nconst','category']].merge(clean_characters_df[['characters','primaryname']], on='nconst')\n",
        "#df[['col1', 'col2']].merge(df2[['col1', 'col3']], on='col1')\n",
        "rdd1 = sc.parallelize(clean_professions_df)\n",
        "rdd2 = sc.parallelize(clean_characters_df)\n",
        "\n",
        "union_rdd = sc.union([rdd1, rdd2])\n",
        "#new_professions_df=clean_characters_df.join(clean_professions_df,\"nconst\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}